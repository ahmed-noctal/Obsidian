1. **Looked at Deepseek Janus , tried to make a gradio app and instal flash attention**
deepseek pro 7 is available at the following page: https://huggingface.co/deepseek-ai/Janus-Pro-7B

It is supposed to be an any-to-any model. Could produce in theory from any modality to any modality. I think that it will not be a great model for video question answering (sounds too good be true for any-to-any models) but one needs to see. 

I pulled the git repo, I wrote a small code to use this model, and push a small gradio app so people can check it. However after a couple of iterations the issue came out to be of flash attention. Only new nvidia gpus a100, and h100 are Ampere architectures, which are expensive and difficult to get from cloud VMs because of longer queues. I tried for about an hour installing flash attention but could not do it. couple of VM starts, etc..
**The code is committed** . Note: 

1. Talked with iftikhar about cleaning the Cloud VM so that we can get rid of an extra hard disk of 8TB costing us 500 dollars a month
2. Tried starting VMs in different region to check availability of different A100 or H100 architectures
3. Tried installing Janus on local macbook as well, with the help of repo. 


**Research Understanding**
Trying to understand the multimodal fusion architecture for 
**"Multimodal Learning using Optimal Transport for Sarcasm and Humor Detection"**